import csv
import os
import time
import logging
from prometheus_client import Gauge, start_http_server

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)

# **è¨­å®š CSV æª”æ¡ˆä¾†æº**
CSV_FILE = "bak-data_collect.csv"

def parse_csv():
    """å¾ `bak-data_collect.csv` è®€å–è³‡æ–™ï¼Œä¸¦å‹•æ…‹è§£ææ¨™ç±¤"""
    counts_basic = {}
    counts_extended = {}
    dynamic_labels = set()  # **å‹•æ…‹æ¨™ç±¤**

    if not os.path.exists(CSV_FILE):
        logging.error(f"CSV æª”æ¡ˆ `{CSV_FILE}` ä¸å­˜åœ¨ï¼")
        return counts_basic, counts_extended, sorted(["host", "job_name"])

    with open(CSV_FILE, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        for row in reader:
            if len(row) < 2:
                continue  # **è‡³å°‘è¦æœ‰ `host` å’Œ `job_name`**

            host = row[0].strip()
            job_name = row[1].strip()
            extra_labels = {}

            # **è§£æ `{}` å…§çš„æ¨™ç±¤**
            for col in row[2:]:
                col = col.strip()

                # **ç§»é™¤ `{}` å¤§æ‹¬è™Ÿ**
                if col.startswith("{") and col.endswith("}"):
                    col = col[1:-1].strip()  

                # **è§£æ `key=value` æ ¼å¼**
                key_value_pairs = col.split(",")
                for pair in key_value_pairs:
                    pair = pair.strip()
                    if "=" in pair:
                        key, value = map(str.strip, pair.split("=", 1))
                        key = key.replace("{", "").replace("}", "").strip()  # **ç¢ºä¿ `key` æ²’æœ‰ `{}`**
                        if key and value:
                            extra_labels[key] = value

            # **æ›´æ–°å‹•æ…‹ Labels**
            dynamic_labels.update(extra_labels.keys())

            # **è¨˜éŒ„åŸºæœ¬è¨ˆæ•¸**
            basic_key = (host, job_name)
            counts_basic[basic_key] = counts_basic.get(basic_key, 0) + 1

            # **è¨˜éŒ„æ“´å±•è¨ˆæ•¸ï¼ˆåŒ…å«é¡å¤–æ¨™ç±¤ï¼‰**
            if extra_labels:
                extended_key = (host, job_name, frozenset(extra_labels.items()))
                counts_extended[extended_key] = counts_extended.get(extended_key, 0) + 1

    # **ç¢ºä¿ `dynamic_labels` åªåŒ…å«æœ‰æ•ˆçš„ key**
    labels_list_extended = sorted(["host", "job_name"] + list(dynamic_labels))

    logging.info(f"Final dynamic_labels: {labels_list_extended}")
    return counts_basic, counts_extended, labels_list_extended

# **åˆå§‹åŒ– Prometheus æŒ‡æ¨™**
counts_basic, counts_extended, labels_list_extended = parse_csv()

# **Metric 1ï¼šåªåŒ…å«åŸºæœ¬ labels**
log_host_job_basic = Gauge(
    "log_host_job_basic",
    "Basic count of occurrences of host and job_name in log",
    ["host", "job_name"]
)

# **Metric 2ï¼šåŒ…å«æ‰€æœ‰å¯èƒ½å‡ºç¾çš„ labelsï¼ˆå‹•æ…‹åµæ¸¬ï¼‰**
log_host_job_extended = Gauge(
    "log_host_job_extended",
    "Extended count of occurrences with additional labels",
    labels_list_extended
)

logging.info(f"[DEBUG] è¨­å®š Prometheus æŒ‡æ¨™")
logging.info(f" - log_host_job_basic Labels: ['host', 'job_name']")
logging.info(f" - log_host_job_extended Labels: {labels_list_extended}")  # ğŸ” Debug

def update_metrics():
    """æ›´æ–° Prometheus æŒ‡æ¨™"""
    log_host_job_basic._metrics.clear()  # **æ¸…é™¤èˆŠæ•¸æ“š**
    log_host_job_extended._metrics.clear()

    counts_basic, counts_extended, labels_list_extended = parse_csv()

    logging.info("\n[DEBUG] æ›´æ–° metrics:")

    # **å¡«å…… `log_host_job_basic`**
    for (host, job), count in counts_basic.items():
        labels_dict = {"host": host, "job_name": job}
        logging.info(f"[DEBUG] è¨­å®š `log_host_job_basic` => {labels_dict} : {count}")  # ğŸ” Debug
        log_host_job_basic.labels(**labels_dict).set(count)  # âœ… ç¢ºä¿æœ‰æ•¸æ“š

    # **å¡«å…… `log_host_job_extended`**
    for (host, job, extra_labels_tuple), count in counts_extended.items():
        extra_labels = dict(extra_labels_tuple)

        # **ç¢ºä¿ `labels_dict` å…§çš„ `keys` èˆ‡ `labels_list_extended` ä¸€è‡´**
        labels_dict = {label: extra_labels.get(label, "") for label in labels_list_extended}
        labels_dict["host"] = host
        labels_dict["job_name"] = job

        # **ç¢ºä¿ `labels_dict` çš„ `keys` é †åºèˆ‡ `labels_list_extended` ä¸€è‡´**
        sorted_labels_dict = {key: labels_dict[key] for key in labels_list_extended}

        logging.info(f"[DEBUG] è¨­å®š `log_host_job_extended` => {sorted_labels_dict} : {count}")  # ğŸ” Debug
        log_host_job_extended.labels(**sorted_labels_dict).set(count)  # âœ… ç¢ºä¿æœ‰æ•¸æ“š

if __name__ == "__main__":
    # **å•Ÿå‹• Prometheus HTTP ä¼ºæœå™¨**
    start_http_server(8080)
    logging.info("Prometheus exporter running on http://localhost:8080/metrics")  # ğŸ” Debug

    # **å®šæœŸæ›´æ–° metrics**
    while True:
        update_metrics()
        time.sleep(10)
