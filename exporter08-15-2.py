import csv
import os
import time
import logging
from prometheus_client import Gauge, start_http_server

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)

# **è¨­å®š CSV æª”æ¡ˆä¾†æº**
CSV_FILE = "bak-data_collect-1.csv"

def parse_csv():
    """å¾ `bak-data_collect-1.csv` è®€å–è³‡æ–™ï¼Œä¸¦å‹•æ…‹è§£ææ¨™ç±¤"""
    counts_basic = {}
    counts_service = {}
    counts_module = {}
    dynamic_labels_service = set()
    dynamic_labels_module = set()

    if not os.path.exists(CSV_FILE):
        logging.error(f"CSV æª”æ¡ˆ `{CSV_FILE}` ä¸å­˜åœ¨ï¼")
        return counts_basic, counts_service, counts_module, ["host", "job_name"], ["host", "job_name"]

    with open(CSV_FILE, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        for row in reader:
            if len(row) < 2:
                continue  # **è‡³å°‘è¦æœ‰ `host` å’Œ `job_name`**

            host = row[0].strip()
            job_name = row[1].strip()
            extra_labels = {}

            # **è§£æ `{}` å…§çš„æ¨™ç±¤**
            for col in row[2:]:
                col = col.strip()

                # **ç§»é™¤ `{}` å¤§æ‹¬è™Ÿ**
                if col.startswith("{") and col.endswith("}"):
                    col = col[1:-1].strip()  

                # **è§£æ `key=value` æ ¼å¼**
                key_value_pairs = col.split(",")
                for pair in key_value_pairs:
                    pair = pair.strip()
                    if "=" in pair:
                        key, value = map(str.strip, pair.split("=", 1))
                        key = key.replace("{", "").replace("}", "").strip()  # **ç¢ºä¿ `key` æ²’æœ‰ `{}`**
                        value = value.replace("â€", "\"").replace("â€œ", "\"")  # ä¿®æ­£å…¨å½¢å¼•è™Ÿ
                        if key and value:
                            extra_labels[key] = value

            # **è¨˜éŒ„åŸºæœ¬è¨ˆæ•¸**
            basic_key = (host, job_name)
            counts_basic[basic_key] = counts_basic.get(basic_key, 0) + 1

            # **æ ¹æ“šæ¨™ç±¤åˆ†é¡åˆ°ä¸åŒ metric**
            if "service_name" in extra_labels or "container_name" in extra_labels:
                service_key = (host, job_name, frozenset({k: v for k, v in extra_labels.items() if k in ["service_name", "container_name"]}.items()))
                counts_service[service_key] = counts_service.get(service_key, 0) + 1
                dynamic_labels_service.update(["service_name", "container_name"])

            if "module_name" in extra_labels:
                module_key = (host, job_name, frozenset({k: v for k, v in extra_labels.items() if k == "module_name"}.items()))
                counts_module[module_key] = counts_module.get(module_key, 0) + 1
                dynamic_labels_module.add("module_name")

    # **å‹•æ…‹æ¨™ç±¤**
    labels_list_service = sorted(["host", "job_name"] + list(dynamic_labels_service))
    labels_list_module = sorted(["host", "job_name"] + list(dynamic_labels_module))

    logging.info(f"Final dynamic_labels_service: {labels_list_service}")
    logging.info(f"Final dynamic_labels_module: {labels_list_module}")

    return counts_basic, counts_service, counts_module, labels_list_service, labels_list_module

# **åˆå§‹åŒ– Prometheus æŒ‡æ¨™**
counts_basic, counts_service, counts_module, labels_list_service, labels_list_module = parse_csv()

# **Metric 1ï¼šåªåŒ…å«åŸºæœ¬ labels**
log_host_job_basic = Gauge(
    "log_host_job_basic",
    "Basic count of occurrences of host and job_name in log",
    ["host", "job_name"]
)

# **Metric 2ï¼šåŒ…å« `service_name, container_name`**
log_host_job_service = Gauge(
    "log_host_job_service",
    "Count of occurrences with service-related labels",
    labels_list_service
)

# **Metric 3ï¼šåŒ…å« `module_name`**
log_host_job_module = Gauge(
    "log_host_job_module",
    "Count of occurrences with module-related labels",
    labels_list_module
)

logging.info(f"[DEBUG] è¨­å®š Prometheus æŒ‡æ¨™")
logging.info(f" - log_host_job_basic Labels: ['host', 'job_name']")
logging.info(f" - log_host_job_service Labels: {labels_list_service}")
logging.info(f" - log_host_job_module Labels: {labels_list_module}")  # ğŸ” Debug

def update_metrics():
    """æ›´æ–° Prometheus æŒ‡æ¨™"""
    log_host_job_basic._metrics.clear()
    log_host_job_service._metrics.clear()
    log_host_job_module._metrics.clear()

    counts_basic, counts_service, counts_module, labels_list_service, labels_list_module = parse_csv()

    logging.info("\n[DEBUG] æ›´æ–° metrics:")

    # **å¡«å…… `log_host_job_basic`**
    for (host, job), count in counts_basic.items():
        labels_dict = {"host": host, "job_name": job}
        logging.info(f"[DEBUG] è¨­å®š `log_host_job_basic` => {labels_dict} : {count}")  # ğŸ” Debug
        log_host_job_basic.labels(**labels_dict).set(count)

    # **å¡«å…… `log_host_job_service`**
    for (host, job, extra_labels_tuple), count in counts_service.items():
        extra_labels = dict(extra_labels_tuple)
        labels_dict = {label: extra_labels.get(label, "") for label in labels_list_service}
        labels_dict["host"] = host
        labels_dict["job_name"] = job
        sorted_labels_dict = {key: labels_dict[key] for key in labels_list_service}
        logging.info(f"[DEBUG] è¨­å®š `log_host_job_service` => {sorted_labels_dict} : {count}")
        log_host_job_service.labels(**sorted_labels_dict).set(count)

    # **å¡«å…… `log_host_job_module`**
    for (host, job, extra_labels_tuple), count in counts_module.items():
        extra_labels = dict(extra_labels_tuple)
        labels_dict = {label: extra_labels.get(label, "") for label in labels_list_module}
        labels_dict["host"] = host
        labels_dict["job_name"] = job
        sorted_labels_dict = {key: labels_dict[key] for key in labels_list_module}
        logging.info(f"[DEBUG] è¨­å®š `log_host_job_module` => {sorted_labels_dict} : {count}")
        log_host_job_module.labels(**sorted_labels_dict).set(count)

if __name__ == "__main__":
    # **å•Ÿå‹• Prometheus HTTP ä¼ºæœå™¨**
    start_http_server(8080)
    logging.info("Prometheus exporter running on http://localhost:8080/metrics")

    # **å®šæœŸæ›´æ–° metrics**
    while True:
        update_metrics()
        time.sleep(10)
